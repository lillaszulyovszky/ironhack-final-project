{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "falling-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup # Text Cleaning\n",
    "import re, string # Regular Expressions, String\n",
    "from nltk.corpus import stopwords # stopwords\n",
    "from nltk.stem.porter import PorterStemmer # for word stemming\n",
    "from nltk.stem import WordNetLemmatizer # for word lemmatization\n",
    "import unicodedata\n",
    "import html\n",
    "import re\n",
    "\n",
    "# read csv\n",
    "df = pd.read_csv('../csv/data_clean.csv')\n",
    "df_prep = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "exciting-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns we want in the df\n",
    "df_prep = df_prep[['channel_name', 'user', 'real_name', 'participant', 'text',\n",
    "       'text_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "controversial-shannon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>user</th>\n",
       "      <th>real_name</th>\n",
       "      <th>participant</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>general</td>\n",
       "      <td>U01S79YDELR</td>\n",
       "      <td>Karina Condeixa</td>\n",
       "      <td>student</td>\n",
       "      <td>Hang told me to add it in education</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>general</td>\n",
       "      <td>U01S79YDELR</td>\n",
       "      <td>Karina Condeixa</td>\n",
       "      <td>student</td>\n",
       "      <td>What improved my score was adding metrics of a...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>general</td>\n",
       "      <td>U01RRV4JX6Z</td>\n",
       "      <td>Francisco Ebeling</td>\n",
       "      <td>student</td>\n",
       "      <td>I feel like a slave to this dumb Resume Worded...</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>general</td>\n",
       "      <td>U01S79YDELR</td>\n",
       "      <td>Karina Condeixa</td>\n",
       "      <td>student</td>\n",
       "      <td>Francisco, we have to remove the fancy/beautif...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>general</td>\n",
       "      <td>U01RRV4JX6Z</td>\n",
       "      <td>Francisco Ebeling</td>\n",
       "      <td>student</td>\n",
       "      <td>Ah, ok!</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel_name         user          real_name participant  \\\n",
       "0      general  U01S79YDELR    Karina Condeixa     student   \n",
       "1      general  U01S79YDELR    Karina Condeixa     student   \n",
       "2      general  U01RRV4JX6Z  Francisco Ebeling     student   \n",
       "3      general  U01S79YDELR    Karina Condeixa     student   \n",
       "4      general  U01RRV4JX6Z  Francisco Ebeling     student   \n",
       "\n",
       "                                                text  text_length  \n",
       "0                Hang told me to add it in education           35  \n",
       "1  What improved my score was adding metrics of a...           98  \n",
       "2  I feel like a slave to this dumb Resume Worded...          261  \n",
       "3  Francisco, we have to remove the fancy/beautif...           76  \n",
       "4                                            Ah, ok!            7  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-kingdom",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "universal-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column dtype into string\n",
    "df_prep['text'] = df_prep['text'].astype(str)\n",
    "\n",
    "# change column to list\n",
    "text_list = df_prep['text'].tolist()\n",
    "\n",
    "# # set of stopwords to be removed from text\n",
    "# stop = set(stopwords.words('english'))\n",
    "\n",
    "# # update stopwords to have punctuation too\n",
    "# stop.update(list(string.punctuation))\n",
    "\n",
    "\n",
    "# utility function for preprocessing the texts\n",
    "def clean_text(text_list):\n",
    "    \n",
    "    # Remove unwanted html characters\n",
    "    re1 = re.compile(r'  +')\n",
    "    x1 = text_list.lower().replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "    'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "    '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>', 'u_n').replace(' @.@ ', '.').replace(\n",
    "    ' @-@ ', '-').replace('\\\\', ' \\\\ ')\n",
    "    text = re1.sub(' ', html.unescape(x1))\n",
    "    \n",
    "    # remove non-ascii characters\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    \n",
    "    # strip html\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    \n",
    "    # remove between square brackets\n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    \n",
    "    # remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # remove twitter tags\n",
    "    text = text.replace(\"<@>\", \"\")\n",
    "    \n",
    "    # remove hashtags\n",
    "    text = text.replace(\"#\", \"\")\n",
    "    \n",
    "    # remove all non-alphabetic characters\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
    "    \n",
    "#     # remove stopwords from text\n",
    "#     final_text = []\n",
    "#     for word in text.split():\n",
    "#         if word.strip().lower() not in stop:\n",
    "#             final_text.append(word.strip().lower())\n",
    "    \n",
    "#     text = \" \".join(final_text)\n",
    "    \n",
    "    # lemmatize words\n",
    "#     lemmatizer = WordNetLemmatizer()    \n",
    "#     text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "#     text = \" \".join([lemmatizer.lemmatize(word, pos = 'v') for word in text.split()])\n",
    "    \n",
    "    # replace all numbers with \"num\"\n",
    "    text = re.sub(\"\\d\", \"num\", text)\n",
    "    \n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "tamil-illness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>user</th>\n",
       "      <th>real_name</th>\n",
       "      <th>participant</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>prep_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>general</td>\n",
       "      <td>U01S79YDELR</td>\n",
       "      <td>Karina Condeixa</td>\n",
       "      <td>student</td>\n",
       "      <td>Hang told me to add it in education</td>\n",
       "      <td>35</td>\n",
       "      <td>hang told me to add it in education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>general</td>\n",
       "      <td>U01S79YDELR</td>\n",
       "      <td>Karina Condeixa</td>\n",
       "      <td>student</td>\n",
       "      <td>What improved my score was adding metrics of a...</td>\n",
       "      <td>98</td>\n",
       "      <td>what improved my score was adding metrics of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>general</td>\n",
       "      <td>U01RRV4JX6Z</td>\n",
       "      <td>Francisco Ebeling</td>\n",
       "      <td>student</td>\n",
       "      <td>I feel like a slave to this dumb Resume Worded...</td>\n",
       "      <td>261</td>\n",
       "      <td>i feel like a slave to this dumb resume worded...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>general</td>\n",
       "      <td>U01S79YDELR</td>\n",
       "      <td>Karina Condeixa</td>\n",
       "      <td>student</td>\n",
       "      <td>Francisco, we have to remove the fancy/beautif...</td>\n",
       "      <td>76</td>\n",
       "      <td>francisco we have to remove the fancybeautiful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>general</td>\n",
       "      <td>U01RRV4JX6Z</td>\n",
       "      <td>Francisco Ebeling</td>\n",
       "      <td>student</td>\n",
       "      <td>Ah, ok!</td>\n",
       "      <td>7</td>\n",
       "      <td>ah ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>general</td>\n",
       "      <td>U01RN7BVD1C</td>\n",
       "      <td>Josephine Biedermann</td>\n",
       "      <td>student</td>\n",
       "      <td>I think today is normal retro at 9\\nThe whole ...</td>\n",
       "      <td>90</td>\n",
       "      <td>i think today is normal retro at the whole sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>general</td>\n",
       "      <td>U01S7BM4N81</td>\n",
       "      <td>Thamo</td>\n",
       "      <td>student</td>\n",
       "      <td>Thank you phine :blush:</td>\n",
       "      <td>23</td>\n",
       "      <td>thank you phine blush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>general</td>\n",
       "      <td>U01RN7BVD1C</td>\n",
       "      <td>Josephine Biedermann</td>\n",
       "      <td>student</td>\n",
       "      <td>:slightly_smiling_face: I hope I'm correct tho...</td>\n",
       "      <td>109</td>\n",
       "      <td>slightlysmilingface i hope im correct though b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>general</td>\n",
       "      <td>U01SJKB2MG8</td>\n",
       "      <td>Florian Titze</td>\n",
       "      <td>teacher</td>\n",
       "      <td>You are correct, Phine!</td>\n",
       "      <td>23</td>\n",
       "      <td>you are correct phine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>general</td>\n",
       "      <td>U01SJKB2MG8</td>\n",
       "      <td>Florian Titze</td>\n",
       "      <td>teacher</td>\n",
       "      <td>&lt;!channel&gt;,\\ngood morning! It's Friday - that ...</td>\n",
       "      <td>225</td>\n",
       "      <td>good morning its friday  that means retro time...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   channel_name         user             real_name participant  \\\n",
       "0       general  U01S79YDELR       Karina Condeixa     student   \n",
       "1       general  U01S79YDELR       Karina Condeixa     student   \n",
       "2       general  U01RRV4JX6Z     Francisco Ebeling     student   \n",
       "3       general  U01S79YDELR       Karina Condeixa     student   \n",
       "4       general  U01RRV4JX6Z     Francisco Ebeling     student   \n",
       "..          ...          ...                   ...         ...   \n",
       "95      general  U01RN7BVD1C  Josephine Biedermann     student   \n",
       "96      general  U01S7BM4N81                 Thamo     student   \n",
       "97      general  U01RN7BVD1C  Josephine Biedermann     student   \n",
       "98      general  U01SJKB2MG8         Florian Titze     teacher   \n",
       "99      general  U01SJKB2MG8         Florian Titze     teacher   \n",
       "\n",
       "                                                 text  text_length  \\\n",
       "0                 Hang told me to add it in education           35   \n",
       "1   What improved my score was adding metrics of a...           98   \n",
       "2   I feel like a slave to this dumb Resume Worded...          261   \n",
       "3   Francisco, we have to remove the fancy/beautif...           76   \n",
       "4                                             Ah, ok!            7   \n",
       "..                                                ...          ...   \n",
       "95  I think today is normal retro at 9\\nThe whole ...           90   \n",
       "96                            Thank you phine :blush:           23   \n",
       "97  :slightly_smiling_face: I hope I'm correct tho...          109   \n",
       "98                            You are correct, Phine!           23   \n",
       "99  <!channel>,\\ngood morning! It's Friday - that ...          225   \n",
       "\n",
       "                                            prep_text  \n",
       "0                 hang told me to add it in education  \n",
       "1   what improved my score was adding metrics of a...  \n",
       "2   i feel like a slave to this dumb resume worded...  \n",
       "3   francisco we have to remove the fancybeautiful...  \n",
       "4                                               ah ok  \n",
       "..                                                ...  \n",
       "95  i think today is normal retro at the whole sta...  \n",
       "96                              thank you phine blush  \n",
       "97  slightlysmilingface i hope im correct though b...  \n",
       "98                              you are correct phine  \n",
       "99  good morning its friday  that means retro time...  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply cleaning function\n",
    "df_prep['prep_text'] = df_prep['text'].apply(clean_text)\n",
    "df_prep.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "starting-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove emoji.\n",
    "def emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "df_prep['prep_text'] = df_prep['prep_text'].apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "statewide-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to excel\n",
    "df_sent.to_excel(r'../csv/data_clean_topic_modelling.xlsx', index = False)\n",
    "# save to csv\n",
    "df_sent.to_csv(r'../csv/data_clean_topic_modelling.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-drove",
   "metadata": {},
   "source": [
    "## Topic Modelling\n",
    "Use TF-IDF Vectorization to create a vectorized document term matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-steering",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ahead-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "beneficial-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_df=0.75, min_df=2, stop_words='english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "damaged-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = tfidf.fit_transform(df_prep['prep_text'].apply(lambda x: np.str_(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "outside-script",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     hang told me to add it in education\n",
       "1       what improved my score was adding metrics of a...\n",
       "2       i feel like a slave to this dumb resume worded...\n",
       "3       francisco we have to remove the fancybeautiful...\n",
       "4                                                   ah ok\n",
       "                              ...                        \n",
       "4935                                 just saw this thanks\n",
       "4936    ill have a think need to develop a strategy to...\n",
       "4937                        heeeellpppanyone ursrend eyes\n",
       "4938          i will have a look after the presentation v\n",
       "4939    i quite like the kaggle explanations been read...\n",
       "Name: prep_text, Length: 4940, dtype: object"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep['prep_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-design",
   "metadata": {},
   "source": [
    "### Non-negative Matrix Factorization\n",
    "\n",
    "Using Scikit-Learn create an instance of NMF with 10 expected components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "standard-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "introductory-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(n_components=10,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "excess-faculty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "    n_components=10, random_state=42, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-madrid",
   "metadata": {},
   "source": [
    "### 15 most common words for each of the 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "greatest-employee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3112"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "reasonable-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "optional-synthetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "options\n",
      "aim\n",
      "staying\n",
      "rename\n",
      "standard\n",
      "passionate\n",
      "enabled\n",
      "dependent\n",
      "reach\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-e9d17c139741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrandom_word_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3301\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_word_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    random_word_id = random.randint(0,3301)\n",
    "    print(tfidf.get_feature_names()[random_word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "handed-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_topic = nmf_model.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "funny-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 15 words for this topic:\n",
    "single_topic.argsort()[-15:]\n",
    "top_word_indices = single_topic.argsort()[-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "random-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jup\n",
      "ones\n",
      "difference\n",
      "apparently\n",
      "lucky\n",
      "run\n",
      "zero\n",
      "interpolate\n",
      "turn\n",
      "staying\n",
      "dont\n",
      "beginning\n",
      "null\n",
      "values\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "for index in top_word_indices:\n",
    "    print(tfidf.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "republican-museum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 15 WORDS FOR TOPIC #0\n",
      "['jup', 'ones', 'difference', 'apparently', 'lucky', 'run', 'zero', 'interpolate', 'turn', 'staying', 'dont', 'beginning', 'null', 'values', 'nan']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #1\n",
      "['learn', 'meet', 'specific', 'room', 'sense', 'file', 'later', 'python', 'using', 'did', 'uskcldf', 'disappointed', 'ah', 'thats', 'yes']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #2\n",
      "['worked', 'francisco', 'trick', 'urnbvdc', 'kosta', 'clarification', 'works', 'ill', 'cool', 'sian', 'flo', 'heart', 'alex', 'thamo', 'thanks']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #3\n",
      "['figure', 'collab', 'zoom', 'worked', 'slot', 'awesome', 'looks', 'works', 'idea', 'sam', 'feedback', 'great', 'got', 'cool', 'slightlysmilingface']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #4\n",
      "['sure', 'right', 'want', 'work', 'lab', 'use', 'time', 'know', 'dont', 'need', 'did', 'data', 'think', 'im', 'just']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #5\n",
      "['easier', 'hope', 'thats', 'problem', 'github', 'want', 'today', 'look', 'thamo', 'haha', 'thx', 'got', 'ahhh', 'ah', 'ok']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #6\n",
      "['fisherman', 'japanese', 'makes', 'raisedhands', 'urwhbp', 'try', 'great', 'helpful', 'got', 'sian', 'usbmn', 'oh', 'guys', 'work', 'thank']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #7\n",
      "['plan', 'walking', 'laptop', 'strollin', 'stuff', 'starstruck', 'solutions', 'havent', 'haha', 'know', 'job', 'looks', 'idea', 'morning', 'good']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #8\n",
      "['feel', 'sian', 'memes', 'sorry', 'understand', 'maybe', 'yea', 'way', 'looks', 'solve', 'day', 'got', 'happening', 'did', 'smile']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #9\n",
      "['doesnt', 'supposed', 'thamo', 'slot', 'work', 'sure', 'urwhbp', 'matrix', 'haha', 'feel', 'thats', 'sounds', 'look', 'looks', 'like']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's view all the 10 topics found.\n",
    "for index,topic in enumerate(nmf_model.components_):\n",
    "    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n",
    "    print([tfidf.get_feature_names()[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-bennett",
   "metadata": {},
   "source": [
    "### Attaching Discovered Topic Labels to Original Articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "encouraging-string",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4940x3112 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 26890 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "premier-annotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4940, 3112)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "exciting-funds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4940"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "disciplinary-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = nmf_model.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "infrared-captain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4940, 10)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "thorough-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep['text_topic'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "vanilla-moisture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>user</th>\n",
       "      <th>real_name</th>\n",
       "      <th>participant</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>prep_text</th>\n",
       "      <th>text_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>general</td>\n",
       "      <td>U01S79YDELR</td>\n",
       "      <td>Karina Condeixa</td>\n",
       "      <td>student</td>\n",
       "      <td>Hang told me to add it in education</td>\n",
       "      <td>35</td>\n",
       "      <td>hang told me to add it in education</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>general</td>\n",
       "      <td>U01S79YDELR</td>\n",
       "      <td>Karina Condeixa</td>\n",
       "      <td>student</td>\n",
       "      <td>What improved my score was adding metrics of a...</td>\n",
       "      <td>98</td>\n",
       "      <td>what improved my score was adding metrics of a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>general</td>\n",
       "      <td>U01RRV4JX6Z</td>\n",
       "      <td>Francisco Ebeling</td>\n",
       "      <td>student</td>\n",
       "      <td>I feel like a slave to this dumb Resume Worded...</td>\n",
       "      <td>261</td>\n",
       "      <td>i feel like a slave to this dumb resume worded...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>general</td>\n",
       "      <td>U01S79YDELR</td>\n",
       "      <td>Karina Condeixa</td>\n",
       "      <td>student</td>\n",
       "      <td>Francisco, we have to remove the fancy/beautif...</td>\n",
       "      <td>76</td>\n",
       "      <td>francisco we have to remove the fancybeautiful...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>general</td>\n",
       "      <td>U01RRV4JX6Z</td>\n",
       "      <td>Francisco Ebeling</td>\n",
       "      <td>student</td>\n",
       "      <td>Ah, ok!</td>\n",
       "      <td>7</td>\n",
       "      <td>ah ok</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>general</td>\n",
       "      <td>U01S79YDELR</td>\n",
       "      <td>Karina Condeixa</td>\n",
       "      <td>student</td>\n",
       "      <td>I just copied each session. without any table,...</td>\n",
       "      <td>99</td>\n",
       "      <td>i just copied each session without any table j...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>general</td>\n",
       "      <td>U01RRV4JX6Z</td>\n",
       "      <td>Francisco Ebeling</td>\n",
       "      <td>student</td>\n",
       "      <td>Yeah, I did this. It has improved, but not qui...</td>\n",
       "      <td>70</td>\n",
       "      <td>yeah i did this it has improved but not quiet ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>general</td>\n",
       "      <td>U01RRV4JX6Z</td>\n",
       "      <td>Francisco Ebeling</td>\n",
       "      <td>student</td>\n",
       "      <td>Did you put career mid level?</td>\n",
       "      <td>29</td>\n",
       "      <td>did you put career mid level</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>general</td>\n",
       "      <td>U01S79YDELR</td>\n",
       "      <td>Karina Condeixa</td>\n",
       "      <td>student</td>\n",
       "      <td>take a look in each feature you need most to i...</td>\n",
       "      <td>101</td>\n",
       "      <td>take a look in each feature you need most to i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>general</td>\n",
       "      <td>U01S79YDELR</td>\n",
       "      <td>Karina Condeixa</td>\n",
       "      <td>student</td>\n",
       "      <td>I put first as junior, later as mid. I had bet...</td>\n",
       "      <td>67</td>\n",
       "      <td>i put first as junior later as mid i had bette...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel_name         user          real_name participant  \\\n",
       "0      general  U01S79YDELR    Karina Condeixa     student   \n",
       "1      general  U01S79YDELR    Karina Condeixa     student   \n",
       "2      general  U01RRV4JX6Z  Francisco Ebeling     student   \n",
       "3      general  U01S79YDELR    Karina Condeixa     student   \n",
       "4      general  U01RRV4JX6Z  Francisco Ebeling     student   \n",
       "5      general  U01S79YDELR    Karina Condeixa     student   \n",
       "6      general  U01RRV4JX6Z  Francisco Ebeling     student   \n",
       "7      general  U01RRV4JX6Z  Francisco Ebeling     student   \n",
       "8      general  U01S79YDELR    Karina Condeixa     student   \n",
       "9      general  U01S79YDELR    Karina Condeixa     student   \n",
       "\n",
       "                                                text  text_length  \\\n",
       "0                Hang told me to add it in education           35   \n",
       "1  What improved my score was adding metrics of a...           98   \n",
       "2  I feel like a slave to this dumb Resume Worded...          261   \n",
       "3  Francisco, we have to remove the fancy/beautif...           76   \n",
       "4                                            Ah, ok!            7   \n",
       "5  I just copied each session. without any table,...           99   \n",
       "6  Yeah, I did this. It has improved, but not qui...           70   \n",
       "7                      Did you put career mid level?           29   \n",
       "8  take a look in each feature you need most to i...          101   \n",
       "9  I put first as junior, later as mid. I had bet...           67   \n",
       "\n",
       "                                           prep_text  text_topic  \n",
       "0                hang told me to add it in education           4  \n",
       "1  what improved my score was adding metrics of a...           4  \n",
       "2  i feel like a slave to this dumb resume worded...           9  \n",
       "3  francisco we have to remove the fancybeautiful...           4  \n",
       "4                                              ah ok           5  \n",
       "5  i just copied each session without any table j...           9  \n",
       "6  yeah i did this it has improved but not quiet ...           4  \n",
       "7                       did you put career mid level           4  \n",
       "8  take a look in each feature you need most to i...           4  \n",
       "9  i put first as junior later as mid i had bette...           4  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-people",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-tunisia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
