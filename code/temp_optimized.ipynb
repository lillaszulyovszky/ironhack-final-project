{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# import basic libraries\n",
    "import os, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "pd.options.mode.chained_assignment = None\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "main_folder_path = '../raw_data' \n",
    "\n",
    "def parse_all_json(main_folder_path):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "### Iterate through the group of folders\n",
    "    for folder in os.listdir(main_folder_path):\n",
    "        folder_path = os.path.join(main_folder_path, folder)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "## Iterate through each individual folder\n",
    "            for file in os.listdir(folder_path):\n",
    "                file = os.path.join(main_folder_path, folder, file)\n",
    "            \n",
    "            #add a channel name column and add which folder is the value coming from: general, labhelp, \n",
    "                if file.endswith('.json'):\n",
    "                    data = pd.read_json(file)\n",
    "                    data['channel_name'] = folder\n",
    "                    df = pd.concat([df, data])\n",
    "    return df\n",
    "\n",
    "#def get_text_content(df):\n",
    "#return df['text']\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "data = parse_all_json('../raw_data/')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# save to csv\n",
    "data.to_csv(r'../csv/data_raw.csv', index = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df = data.copy()\n",
    "\n",
    "df_clean = df.copy()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def clean_dataframe(df_clean):\n",
    "    \"\"\"this function is applied to clean the dataframe\n",
    "    \"\"\"\n",
    "    # drop columns not needed\n",
    "    df_clean.drop(['type', 'client_msg_id', 'team', 'user_team',\n",
    "             'source_team', 'blocks', 'upload', 'display_as_bot',\n",
    "             'thread_ts', 'latest_reply', 'is_locked', 'subscribed',\n",
    "             'parent_user_id', 'bot_id', 'bot_profile', 'last_read', 'edited',\n",
    "             'purpose', 'inviter', 'topic', 'root', 'old_name', 'name', 'hidden',\n",
    "             'x_files'], axis=1, inplace=True)\n",
    "    \n",
    "    # filter out for the rows which has subtype values\n",
    "    df_clean = df_clean[(df_clean.subtype != 'channel_join') & \n",
    "                                (df_clean.subtype != 'channel_join') &\n",
    "                                (df_clean.subtype != 'channel_purpose') &\n",
    "                                (df_clean.subtype != 'thread_broadcast')]\n",
    "    # drop subtype column with the values we don't need anymore\n",
    "    df_clean.drop('subtype', axis=1, inplace=True) \n",
    "    \n",
    "    return df_clean"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def datetime_wrangling(df_clean):\n",
    "    \n",
    "    \"\"\"this function is applied to summarise wrangling steps with datetime\n",
    "    \"\"\"\n",
    "    # convert ts to datetime from float\n",
    "    df_clean['ts'] = pd.to_datetime(df_clean['ts'], unit='s').astype('datetime64[s]')\n",
    "    \n",
    "    # create a column for the days of the week using the ts column\n",
    "    df_clean['day_name'] = df_clean['ts'].dt.day_name()\n",
    "    df_clean['day_number'] = pd.DatetimeIndex(df_clean['ts']).day\n",
    "    \n",
    "    # create a column for the months of the year using the ts column\n",
    "    df_clean['month'] = pd.DatetimeIndex(df_clean['ts']).month\n",
    "\n",
    "    # convert values to date time and then month names\n",
    "    df_clean['month'] = pd.to_datetime(df_clean['month'], format='%m').dt.month_name()\n",
    "    \n",
    "    # create a column for the type of the weekday using the ts column\n",
    "    df_clean['day_type'] = df_clean.ts.dt.weekday.apply(\n",
    "    lambda x: 'Weekday' if x < 5 else 'Weekend')\n",
    "    \n",
    "    # create a column for the hour of the day using the ts column\n",
    "    df_clean['time']= df_clean['ts'].dt.strftime('%H')\n",
    "    \n",
    "    # create a column for the parts of the day\n",
    "    df_clean['dayparts'] = (df_clean['ts'].dt.hour % 24 + 4) // 4\n",
    "    df_clean['dayparts'].replace({1: 'Late Night',\n",
    "                      2: 'Early Morning',\n",
    "                      3: 'Morning',\n",
    "                      4: 'Afternoon',\n",
    "                      5: 'Evening',\n",
    "                      6: 'Night'}, inplace=True)\n",
    "    # drop ts column\n",
    "    df_clean.drop('ts', axis=1, inplace=True) \n",
    "\n",
    "    \n",
    "    return df_clean"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def return_attachments(txt):\n",
    "    \"\"\"this function is applied to column attachments to extract links\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dictionary = (txt)[0]\n",
    "        if 'original_url' in dictionary:\n",
    "            return dictionary.get('original_url', 'None')\n",
    "    except:\n",
    "        return 'None'\n",
    "    \n",
    "df_clean['attachments'] = df_clean['attachments'].apply(return_attachments)\n",
    "#df_clean.to_csv(r'../csv/links.csv', columns = header, index = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def real_name(x):\n",
    "    \"\"\"this function is applied to column user_profile to extract real_name\n",
    "    \"\"\"\n",
    "    if x != x:\n",
    "        return 'noname'\n",
    "    else:\n",
    "        return x['real_name']\n",
    "\n",
    "    \n",
    "df_clean['real_name'] = df_clean['user_profile'].apply(real_name)\n",
    "\n",
    "# drop user_profile column\n",
    "df_clean.drop('user_profile', axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def reactions_count(txt):\n",
    "    \"\"\"this function is applied to column reactions to count reactions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dictionary = eval(txt)[0]\n",
    "        if 'reactions' in dictionary:\n",
    "            return dictionary.get('reactions', 'None')\n",
    "    except:\n",
    "        return 'None'\n",
    "    \n",
    "df_clean['reactions_count'] = df_clean['reactions'].apply(reactions_count)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def reactions_name(txt):\n",
    "    \"\"\"this function is applied to column reactions to count them\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        dictionary = eval(txt)[0]\n",
    "        if 'name' in dictionary:\n",
    "            return dictionary.get('name', 'None')\n",
    "    except:\n",
    "        return 'None'\n",
    "\n",
    "df_clean['reactions_name'] = df_clean['reactions'].apply(reactions_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def boolean_features(df_clean):\n",
    "    \"\"\"this function is applied to create a new column with boolean features\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a new boolean column if comment has reaction\n",
    "    df_clean['reaction_true'] = df_clean['reactions_name'].isna()\n",
    "\n",
    "    # create a new boolean column if comment has reply\n",
    "    df_clean['replies_true'] = df_clean['reply_count'].isna()\n",
    "\n",
    "    # create a new boolean column if comment has attachments\n",
    "    df_clean['attachments_true'] = df_clean['attachments'].isna()\n",
    "    \n",
    "    return df_clean"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def type_of_participant(s):\n",
    "    \"\"\"this function is applied to create a new column with teaching and students\n",
    "    \"\"\"\n",
    "    if s == 'siand the LT (she/her)':\n",
    "        return 'teacher'\n",
    "    if s ==  'Florian Titze':\n",
    "        return 'teacher'\n",
    "    if s ==  'Kosta':\n",
    "        return 'teacher'\n",
    "    else:\n",
    "        return 'student'\n",
    "    return ''\n",
    "\n",
    "# apply\n",
    "df_clean['participant'] = df_clean['real_name'].apply(type_of_participant)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def text_length(df_clean):\n",
    "    \"\"\"this function is applied to create a new column with text length\n",
    "    \"\"\"\n",
    "    df_clean['text_length'] = df_clean['text'].astype(str).map(len)\n",
    "    \n",
    "    return df_clean"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "df_clean = clean_dataframe(df_clean)\n",
    "df_clean = datetime_wrangling(df_clean)\n",
    "df_clean = boolean_features(df_clean)\n",
    "df_clean = text_length(df_clean)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def clean_post_feature_eng(df_clean):\n",
    "    \n",
    "   # droppig unneccessary columns\n",
    "    df_clean.drop(['reactions', 'reply_users', 'replies'], axis=1, inplace=True)\n",
    "    \n",
    "    # replace None values with zero\n",
    "    df_clean['reply_count'] = df_clean['reply_count'].fillna(0)\n",
    "    df_clean['reply_users_count'] = df_clean['reply_users_count'].fillna(0)\n",
    "    df_clean['reply_count'] = df_clean['reply_count'].astype(int)\n",
    "    df_clean['reply_users_count'] = df_clean['reply_users_count'].astype(int)\n",
    "    \n",
    "    # reordering columns\n",
    "    df_clean = df_clean[['channel_name', 'user', 'real_name', 'participant',\n",
    "                     'text', 'text_length', 'reply_count', 'reply_users_count',\n",
    "                     'replies_true', 'day_name', 'day_type', 'time',\n",
    "                     'dayparts', 'day_number', 'month', 'reactions_count', \n",
    "                     'reactions_name', 'attachments', 'attachments_true', 'reaction_true']]\n",
    "    \n",
    "    return df_clean"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "df_clean = clean_post_feature_eng(df_clean)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "df_clean.to_csv(r'../csv/data_clean_optimized.csv', index = False)\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "efc8bafc4d758f486988f8d2efdda8600090a7a8cf09b7978310c03f7f9bdeb6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}